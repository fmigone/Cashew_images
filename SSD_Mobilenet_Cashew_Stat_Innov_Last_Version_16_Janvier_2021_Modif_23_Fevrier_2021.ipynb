{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SSD_Mobilenet_Cashew_Stat_Innov_Last_Version_16_Janvier_2021_Modif_23_Fevrier_2021",
      "provenance": [],
      "collapsed_sections": [
        "yhzxsJb3dpWq",
        "w4V-XE6kbkc1",
        "bI8__uNS8-ns",
        "RVWokrmha7Aq",
        "u-k7uGThXlny",
        "83zjOUigTKwL",
        "SuTZCivmUMx6",
        "UbbBkDk1D6Z8",
        "23TECXvNezIF",
        "JDddx2rPfex9",
        "OmSESMetj1sa",
        "ISvrJKqASgug"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fmigone/Cashew_images/blob/master/SSD_Mobilenet_Cashew_Stat_Innov_Last_Version_16_Janvier_2021_Modif_23_Fevrier_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glHZ94aDihTX"
      },
      "source": [
        "Note! For a most up to date version of this notebook, make sure you copy from:\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1wTMIrJhYsQdq_u7ROOkf0Lu_fsX5Mu8a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQCnYPVDrsgx"
      },
      "source": [
        "## **Training MobileNetSSD Object Detection on a Custom Dataset SINDEV Cashew**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhzxsJb3dpWq"
      },
      "source": [
        "## Configs and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnNXNQCjdniL"
      },
      "source": [
        "# If you forked the repo, you can replace the link.\n",
        "repo_url = 'https://github.com/roboflow-ai/tensorflow-object-detection-faster-rcnn'\n",
        "\n",
        "# Number of training steps - 1000 will train very quickly, but more steps will increase accuracy.\n",
        "num_steps = 1  # 200000 to improve\n",
        "\n",
        "# Number of evaluation steps.\n",
        "num_eval_steps = 1\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "        'batch_size': 8\n",
        "    },    \n",
        "}\n",
        "\n",
        "# Pick the model you want to use\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "selected_model = 'ssd_mobilenet_v2'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL8oRGC5UgMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b26840aa-b795-4d4e-ffe2-ff746927944c"
      },
      "source": [
        "# use TF 1.x for Object Detection APIs as they are not ported to TF 2.0 yet\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4V-XE6kbkc1"
      },
      "source": [
        "## Clone the `tensorflow-object-detection` repository or your fork."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxc3DmvLQF3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18a42822-ce42-4c6b-c128-5f4cbe743cdb"
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'tensorflow-object-detection-faster-rcnn'...\n",
            "remote: Enumerating objects: 885, done.\u001b[K\n",
            "remote: Total 885 (delta 0), reused 0 (delta 0), pack-reused 885\u001b[K\n",
            "Receiving objects: 100% (885/885), 24.84 MiB | 40.24 MiB/s, done.\n",
            "Resolving deltas: 100% (412/412), done.\n",
            "/content/tensorflow-object-detection-faster-rcnn\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI8__uNS8-ns"
      },
      "source": [
        "## Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecpHEnka8Kix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfeb1016-1ebb-426e-ba8c-357309439fd1"
      },
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!pip install tf_slim\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -q pycocotools\n",
        "\n",
        "!pip install lvis\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Collecting tf_slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 16.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 146442 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.3) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.4_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.4) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.3) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.4) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting lvis\n",
            "  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.6/dist-packages (from lvis) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (2.8.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (1.15.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.6/dist-packages (from lvis) (4.1.2.30)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (0.10.0)\n",
            "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.6/dist-packages (from lvis) (0.29.21)\n",
            "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.6/dist-packages (from lvis) (1.19.5)\n",
            "Installing collected packages: lvis\n",
            "Successfully installed lvis-0.5.3\n",
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVWokrmha7Aq"
      },
      "source": [
        "## Importation des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aTFVPkLS21w"
      },
      "source": [
        "repo_url = 'https://github.com/Abubakr05/Cashew_images'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSIX9NqUS8lu",
        "outputId": "aa622a89-aa8c-4a7c-b4b1-0af62390e3d4"
      },
      "source": [
        "import os\n",
        "%cd /content\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'Cashew_images'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 8112 (delta 12), reused 0 (delta 0), pack-reused 8086\u001b[K\n",
            "Receiving objects: 100% (8112/8112), 2.04 GiB | 49.55 MiB/s, done.\n",
            "Resolving deltas: 100% (4313/4313), done.\n",
            "Checking out files: 100% (3802/3802), done.\n",
            "/content/Cashew_images\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-k7uGThXlny"
      },
      "source": [
        "## Prepare `tfrecord` files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNfIPc5yxDOv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8a4ff71-d0ae-4722-c546-32b236a1bfd0"
      },
      "source": [
        "%cd /content/tensorflow-object-detection-faster-rcnn/data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/tensorflow-object-detection-faster-rcnn/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83zjOUigTKwL"
      },
      "source": [
        "#### Reorgarnisation de l'espace de travail"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bC5Ay1nTVAk",
        "outputId": "4a433860-643e-421b-a862-b6eb5df9b963"
      },
      "source": [
        "%cd /content/Cashew_images/data\n",
        "!mkdir -p  \"images\"\n",
        "!mkdir -p  \"annotations\"\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Cashew_images/data\n",
            "/content/Cashew_images/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9eunwsPTY8_",
        "outputId": "f2f115e8-976f-4746-ac21-38542d8ae704"
      },
      "source": [
        "%cd /content/Cashew_images/data/images/\n",
        "!mkdir -p  \"train\"\n",
        "!mkdir -p  \"test\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Cashew_images/data/images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEWFsW94TdTX"
      },
      "source": [
        "#combiner les différents dossiers train provenant du repos github en un seul dossier train\n",
        "import shutil\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_yipTbhUCAM"
      },
      "source": [
        "#deplacement des images du train\n",
        "#dossier=[\"train1\",\"train2\",\"train3\",\"train4\",\"train5\",\"train6\"]\n",
        "dossier=[\"train1\",\"train2\",\"train3\",\"train4\"]\n",
        "for item in dossier:\n",
        "\tsource = \"/content/Cashew_images/data/\"+item\n",
        "\tdestination = \"/content/Cashew_images/data/images/train/\"\n",
        "\n",
        "\tfiles = os.listdir(source)\n",
        "\n",
        "\tfor file in files:\n",
        "\t\tnew_path = shutil.move(f\"{source}/{file}\", destination)\n",
        "\t\t#print(new_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz3_kGBXTfgh"
      },
      "source": [
        "#deplacement des images du test\n",
        "dossier=[\"test\"]\n",
        "for item in dossier:\n",
        "\tsource = \"/content/Cashew_images/data/test\"\n",
        "\tdestination = \"/content/Cashew_images/data/images/test/\"\n",
        "\n",
        "\tfiles = os.listdir(source)\n",
        "\n",
        "\tfor file in files:\n",
        "\t\tnew_path = shutil.move(f\"{source}/{file}\", destination)\n",
        "\t\t#print(new_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuTZCivmUMx6"
      },
      "source": [
        "#### Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha4axm5bUOdG"
      },
      "source": [
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
        "from imgaug import augmenters as iaa "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J632mp0vUP9_"
      },
      "source": [
        "#fonction pour convertir les fichiers XML en un seul fichier CSV\n",
        "def xml_to_csv(path):\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for member in root.findall('object'):\n",
        "            value = (root.find('filename').text,\n",
        "                     float(root.find('size')[0].text),\n",
        "                     float(root.find('size')[1].text),\n",
        "                     member[0].text,\n",
        "                     float(member[4][0].text),\n",
        "                     float(member[4][1].text),\n",
        "                     float(member[4][2].text),\n",
        "                     float(member[4][3].text)\n",
        "                     )\n",
        "            xml_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-9FEV9sUSBI"
      },
      "source": [
        "#conversion des annotation xml en csv - creation d'un fichier csv contenant les annotations\n",
        "#train \n",
        "labels_df_finale_last_train = xml_to_csv('/content/Cashew_images/data/images/train/')\n",
        "labels_df_finale_last_train.to_csv(('/content/Cashew_images/data/labels_train_finales.csv'), index=None)\n",
        "#test\n",
        "labels_df_finale_last_test = xml_to_csv('/content/Cashew_images/data/images/test/')\n",
        "labels_df_finale_last_train.to_csv(('/content/Cashew_images/data/labels_test_finales.csv'), index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ65dPLxUr2y"
      },
      "source": [
        "#fonctions utiles pour la data augmentation à l'aide d'Image Aug\n",
        "def bbs_obj_to_df(bbs_object):\n",
        "#     convert BoundingBoxesOnImage object into array\n",
        "    bbs_array = bbs_object.to_xyxy_array()\n",
        "#     convert array into a DataFrame ['xmin', 'ymin', 'xmax', 'ymax'] columns\n",
        "    df_bbs = pd.DataFrame(bbs_array, columns=['xmin', 'ymin', 'xmax', 'ymax'])\n",
        "    return df_bbs\n",
        "\n",
        "def resize_imgaug(df, images_path, aug_images_path, image_prefix):\n",
        "    # create data frame which we're going to populate with augmented image info\n",
        "    aug_bbs_xy = pd.DataFrame(columns=\n",
        "                              ['filename','width','height','class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "                             )\n",
        "    grouped = df.groupby('filename')    \n",
        "\n",
        "    for filename in df['filename'].unique():\n",
        "    #   Get separate data frame grouped by file name\n",
        "        group_df = grouped.get_group(filename)\n",
        "        group_df = group_df.reset_index()\n",
        "        group_df = group_df.drop(['index'], axis=1)\n",
        "\n",
        "    #   If image height is greater than or equal to image width \n",
        "    #   AND greater than 600px perform resizing augmentation shrinking image height to 600px.\n",
        "        if group_df['height'].unique()[0] >= group_df['width'].unique()[0] and group_df['height'].unique()[0] > 600:\n",
        "        #   read the image\n",
        "            image = imageio.imread(images_path+filename)\n",
        "        #   get bounding boxes coordinates and write into array        \n",
        "            bb_array = group_df.drop(['filename', 'width', 'height', 'class'], axis=1).values\n",
        "        #   pass the array of bounding boxes coordinates to the imgaug library\n",
        "            bbs = BoundingBoxesOnImage.from_xyxy_array(bb_array, shape=image.shape)\n",
        "        #   apply augmentation on image and on the bounding boxes\n",
        "            image_aug, bbs_aug = height_resize(image=image, bounding_boxes=bbs)\n",
        "        #   write augmented image to a file\n",
        "            imageio.imwrite(aug_images_path+image_prefix+filename, image_aug)  \n",
        "        #   create a data frame with augmented values of image width and height\n",
        "            info_df = group_df.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis=1)        \n",
        "            for index, _ in info_df.iterrows():\n",
        "                info_df.at[index, 'width'] = image_aug.shape[1]\n",
        "                info_df.at[index, 'height'] = image_aug.shape[0]\n",
        "        #   rename filenames by adding the predifined prefix\n",
        "            info_df['filename'] = info_df['filename'].apply(lambda x: image_prefix+x)\n",
        "        #   create a data frame with augmented bounding boxes coordinates using the function we created earlier\n",
        "            bbs_df = bbs_obj_to_df(bbs_aug)\n",
        "        #   concat all new augmented info into new data frame\n",
        "            aug_df = pd.concat([info_df, bbs_df], axis=1)\n",
        "        #   append rows to aug_bbs_xy data frame\n",
        "            aug_bbs_xy = pd.concat([aug_bbs_xy, aug_df])\n",
        "\n",
        "    #   if image width is greater than image height \n",
        "    #   AND greater than 600px perform resizing augmentation shrinking image width to 600px\n",
        "        elif group_df['width'].unique()[0] > group_df['height'].unique()[0] and group_df['width'].unique()[0] > 600:\n",
        "        #   read the image\n",
        "            image = imageio.imread(images_path+filename)\n",
        "        #   get bounding boxes coordinates and write into array        \n",
        "            bb_array = group_df.drop(['filename', 'width', 'height', 'class'], axis=1).values\n",
        "        #   pass the array of bounding boxes coordinates to the imgaug library\n",
        "            bbs = BoundingBoxesOnImage.from_xyxy_array(bb_array, shape=image.shape)\n",
        "        #   apply augmentation on image and on the bounding boxes\n",
        "            image_aug, bbs_aug = width_resize(image=image, bounding_boxes=bbs)\n",
        "        #   write augmented image to a file\n",
        "            imageio.imwrite(aug_images_path+image_prefix+filename, image_aug)  \n",
        "        #   create a data frame with augmented values of image width and height\n",
        "            info_df = group_df.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis=1)        \n",
        "            for index, _ in info_df.iterrows():\n",
        "                info_df.at[index, 'width'] = image_aug.shape[1]\n",
        "                info_df.at[index, 'height'] = image_aug.shape[0]\n",
        "        #   rename filenames by adding the predifined prefix\n",
        "            info_df['filename'] = info_df['filename'].apply(lambda x: image_prefix+x)\n",
        "        #   create a data frame with augmented bounding boxes coordinates using the function we created earlier\n",
        "            bbs_df = bbs_obj_to_df(bbs_aug)\n",
        "        #   concat all new augmented info into new data frame\n",
        "            aug_df = pd.concat([info_df, bbs_df], axis=1)\n",
        "        #   append rows to aug_bbs_xy data frame\n",
        "            aug_bbs_xy = pd.concat([aug_bbs_xy, aug_df])\n",
        "\n",
        "    #     append image info without any changes if it's height and width are both less than 600px \n",
        "        else:\n",
        "            aug_bbs_xy = pd.concat([aug_bbs_xy, group_df])\n",
        "    # return dataframe with updated images and bounding boxes annotations \n",
        "    aug_bbs_xy = aug_bbs_xy.reset_index()\n",
        "    aug_bbs_xy = aug_bbs_xy.drop(['index'], axis=1)\n",
        "    return aug_bbs_xy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSKInpVjUsoE"
      },
      "source": [
        "#fonctions utiles pour la data augmentation à l'aide d'Image Aug\n",
        "def image_aug(df, images_path, aug_images_path, image_prefix, augmentor):\n",
        "    # create data frame which we're going to populate with augmented image info\n",
        "    aug_bbs_xy = pd.DataFrame(columns=\n",
        "                              ['filename','width','height','class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "                             )\n",
        "    grouped = df.groupby('filename')\n",
        "    \n",
        "    for filename in df['filename'].unique():\n",
        "    #   get separate data frame grouped by file name\n",
        "        group_df = grouped.get_group(filename)\n",
        "        group_df = group_df.reset_index()\n",
        "        group_df = group_df.drop(['index'], axis=1)   \n",
        "    #   read the image\n",
        "        image = imageio.imread(images_path+filename)\n",
        "    #   get bounding boxes coordinates and write into array        \n",
        "        bb_array = group_df.drop(['filename', 'width', 'height', 'class'], axis=1).values\n",
        "    #   pass the array of bounding boxes coordinates to the imgaug library\n",
        "        bbs = BoundingBoxesOnImage.from_xyxy_array(bb_array, shape=image.shape)\n",
        "    #   apply augmentation on image and on the bounding boxes\n",
        "        image_aug, bbs_aug = augmentor(image=image, bounding_boxes=bbs)\n",
        "    #   disregard bounding boxes which have fallen out of image pane    \n",
        "        bbs_aug = bbs_aug.remove_out_of_image()\n",
        "    #   clip bounding boxes which are partially outside of image pane\n",
        "        bbs_aug = bbs_aug.clip_out_of_image()\n",
        "        \n",
        "    #   don't perform any actions with the image if there are no bounding boxes left in it    \n",
        "        if re.findall('Image...', str(bbs_aug)) == ['Image([]']:\n",
        "            pass\n",
        "        \n",
        "    #   otherwise continue\n",
        "        else:\n",
        "        #   write augmented image to a file\n",
        "            try:\n",
        "                imageio.imwrite(aug_images_path+image_prefix+filename, image_aug)\n",
        "            except:\n",
        "                pass\n",
        "        #   create a data frame with augmented values of image width and height\n",
        "            info_df = group_df.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis=1)    \n",
        "            for index, _ in info_df.iterrows():\n",
        "                info_df.at[index, 'width'] = image_aug.shape[1]\n",
        "                info_df.at[index, 'height'] = image_aug.shape[0]\n",
        "        #   rename filenames by adding the predifined prefix\n",
        "            info_df['filename'] = info_df['filename'].apply(lambda x: image_prefix+x)\n",
        "        #   create a data frame with augmented bounding boxes coordinates using the function we created earlier\n",
        "            bbs_df = bbs_obj_to_df(bbs_aug)\n",
        "        #   concat all new augmented info into new data frame\n",
        "            aug_df = pd.concat([info_df, bbs_df], axis=1)\n",
        "        #   append rows to aug_bbs_xy data frame\n",
        "            aug_bbs_xy = pd.concat([aug_bbs_xy, aug_df])            \n",
        "    \n",
        "    # return dataframe with updated images and bounding boxes annotations \n",
        "    aug_bbs_xy = aug_bbs_xy.reset_index()\n",
        "    aug_bbs_xy = aug_bbs_xy.drop(['index'], axis=1)\n",
        "    return aug_bbs_xy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuAcJdsWU0zM"
      },
      "source": [
        "#Sequence d'augmentation - elle définit quelle opération sera réalisée dans le cadre de l'augmentation\n",
        "aug = iaa.Sequential([\n",
        "    iaa.Affine(rotate=(-10,10)),\n",
        "    iaa.AdditiveGaussianNoise(scale=(0.05*255, 0.05*255)),\n",
        "    iaa.Multiply(1.25)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NslNdGTVaXr"
      },
      "source": [
        "#definition du dossier des données d'images initiales\n",
        "image_init_train = '/content/Cashew_images/data/images/train/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTzYvP9CVTrV"
      },
      "source": [
        "## Realisation de l'augmentation pour les données train\n",
        "augmented_images_df_train = image_aug(labels_df_finale_last_train, image_init_train, image_init_train, 'aug1_', aug)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN2Z0JTtVn90"
      },
      "source": [
        "#definition du dossier des données d'images initiales\n",
        "image_init_test = '/content/Cashew_images/data/images/test/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck75TOl8Vpmz"
      },
      "source": [
        "## Realisation de l'augmentation pour les données train\n",
        "augmented_images_df_test = image_aug(labels_df_finale_last_test, image_init_test, image_init_test, 'aug1_', aug)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxuZ0e3fVvFL"
      },
      "source": [
        "#on crée une fonction true_name pour récupérer le nom des images sans l'extension \".jpg\" dans le but de faire les fichiers d'annotations au format yolo plus tard\n",
        "def true_name(f):\n",
        "  return f.split('.jpg')[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL5UdLo0V6rS"
      },
      "source": [
        "data_csv_train = pd.concat([augmented_images_df_train,labels_df_finale_last_train])\n",
        "data_csv_test = pd.concat([augmented_images_df_test,labels_df_finale_last_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H72p2dOFWgef"
      },
      "source": [
        "data_csv_train['name'] = data_csv_train['filename'].apply (lambda row: true_name(row))\n",
        "data_csv_test['name'] = data_csv_test['filename'].apply (lambda row: true_name(row))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6oUqnHBWSjJ"
      },
      "source": [
        "data_csv_train.dropna(subset = [\"xmin\"], inplace=True)\n",
        "data_csv_test.dropna(subset = [\"xmin\"], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EvbwiFyd2hU"
      },
      "source": [
        "data_csv_train.to_csv(('/content/Cashew_images/data/data_csv_train.csv'), index=None)\r\n",
        "data_csv_test.to_csv(('/content/Cashew_images/data/data_csv_test.csv'), index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkfcNolFWwkY"
      },
      "source": [
        "####  Conversion des annotations CSV en TFRecord\r\n",
        "#### May help : https://stackoverflow.com/questions/52870674/how-to-fix-missing-files-or-folder-error-file-generate-tfrecord-py-line-110"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKJM2p68cdQ6"
      },
      "source": [
        "!python generate_tfrecord.py --csv_input='/content/Cashew_images/data/data_csv_train.csv'  --output_path='/content/Cashew_images/data/train.record'\r\n",
        "!python generate_tfrecord.py --csv_input='/content/Cashew_images/data/data_csv_train.csv'  --output_path='/content/Cashew_images/data/test.record'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIfOmNoIWzVH",
        "outputId": "ff9a64a5-b1f2-4c0d-cf15-d1c7e3779a80"
      },
      "source": [
        "#recupération de la liste des éléments des classes\n",
        "%cd '/content/Cashew_images/data'\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "classes_names = []\n",
        "data = pd.read_excel('/content/Cashew_images/class.xlsx',index_col=None)\n",
        "classes_names = data['label'].tolist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Cashew_images/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t4o_FKCaQS5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6qI1uVamksZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b611180-af1c-4b3c-8552-9e7ad31eba13"
      },
      "source": [
        "# training set\n",
        "%ls train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cashew_label_map.pbtxt  cashew.tfrecord\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEKOjMejmm9U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4368ed8c-de83-42a0-9c30-ecabb10180b0"
      },
      "source": [
        "# test set\n",
        "%ls test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cashew_label_map.pbtxt  cashew.tfrecord\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgd-fzAIkZlV"
      },
      "source": [
        "# NOTE: Update these TFRecord names from \"cells\" and \"cells_label_map\" to your files!\n",
        "test_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/test/cashew.tfrecord'\n",
        "train_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/cashew.tfrecord'\n",
        "label_map_pbtxt_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/cashew_label_map.pbtxt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCNYAaC7w6N8"
      },
      "source": [
        "## Téléchargement du Modèle de Base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orDCj6ihgUMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d04d47b-f613-4848-a7ad-448e6c103bd3"
      },
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGhvAObeiIix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc7b8af6-3f43-495a-c6dc-9e829700da1b"
      },
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/pretrained_model\n",
            "total 135M\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n",
            "drwxr-xr-x 24 root   root  4.0K Feb 16 13:29 ..\n",
            "-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n",
            "-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHnxlfRznPP3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "22d7edff-181b-485c-a68f-909412b4d88f"
      },
      "source": [
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvwtHlLOeRJD"
      },
      "source": [
        "## Configuring a Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIhw7IdpLuiU"
      },
      "source": [
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG1nCNpUXcRU"
      },
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjtCbLF2i0wI"
      },
      "source": [
        "import re\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH0MEEanocn6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fa5d656-222c-46fe-c7b8-e5425fc1a768"
      },
      "source": [
        "!cat {pipeline_fname}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    num_classes: 11\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    anchor_generator {\n",
            "      ssd_anchor_generator {\n",
            "        num_layers: 6\n",
            "        min_scale: 0.2\n",
            "        max_scale: 0.95\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        aspect_ratios: 3.0\n",
            "        aspect_ratios: 0.3333\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 300\n",
            "        width: 300\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      convolutional_box_predictor {\n",
            "        min_depth: 0\n",
            "        max_depth: 0\n",
            "        num_layers_before_predictor: 0\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 0.8\n",
            "        kernel_size: 1\n",
            "        box_code_size: 4\n",
            "        apply_sigmoid_to_scores: false\n",
            "        conv_hyperparams {\n",
            "          activation: RELU_6,\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            truncated_normal_initializer {\n",
            "              stddev: 0.03\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            train: true,\n",
            "            scale: true,\n",
            "            center: true,\n",
            "            decay: 0.9997,\n",
            "            epsilon: 0.001,\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_mobilenet_v2'\n",
            "      min_depth: 16\n",
            "      depth_multiplier: 1.0\n",
            "      conv_hyperparams {\n",
            "        activation: RELU_6,\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            stddev: 0.03\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          train: true,\n",
            "          scale: true,\n",
            "          center: true,\n",
            "          decay: 0.9997,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid {\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      hard_example_miner {\n",
            "        num_hard_examples: 3000\n",
            "        iou_threshold: 0.99\n",
            "        loss_type: CLASSIFICATION\n",
            "        max_negatives_per_positive: 3\n",
            "        min_negatives_per_image: 3\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 12\n",
            "  optimizer {\n",
            "    rms_prop_optimizer: {\n",
            "      learning_rate: {\n",
            "        exponential_decay_learning_rate {\n",
            "          initial_learning_rate: 0.004\n",
            "          decay_steps: 800720\n",
            "          decay_factor: 0.95\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "      decay: 0.9\n",
            "      epsilon: 1.0\n",
            "    }\n",
            "  }\n",
            "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
            "  fine_tune_checkpoint_type:  \"detection\"\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 1\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    ssd_random_crop {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/cashew.tfrecord\"\n",
            "  }\n",
            "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/cashew_label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  num_examples: 8000\n",
            "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
            "  # Remove the below line to evaluate indefinitely.\n",
            "  max_evals: 10\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/test/cashew.tfrecord\"\n",
            "  }\n",
            "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/cashew_label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f11w0uO3jFCB"
      },
      "source": [
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbbBkDk1D6Z8"
      },
      "source": [
        "## Configuring CUDA on Colab "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnRxFzwmBICw",
        "outputId": "a02c7c33-6c7e-4db8-a079-a93807db204e"
      },
      "source": [
        "# CUDA: Let's check that Nvidia CUDA drivers are already pre-installed and which version is it. This can be helpful for debugging.\n",
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0Xb3wJ6EIOy"
      },
      "source": [
        "**IMPORTANT!** If you're not training on a Tesla P100 GPU, we will need to tweak our Darknet configuration later based on what type of GPU we have. Let's set that now while we're inspecting the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTg33jGmEPn0",
        "outputId": "e20d2577-e071-49f0-952c-42bb4ee0c89d"
      },
      "source": [
        "#take a look at the kind of GPU we have\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Feb 16 13:32:21 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHsHect6EUUI",
        "outputId": "8ee90eb7-7f65-45a9-f2a9-5e48cafc9fe5"
      },
      "source": [
        "# Change the number depending on what GPU is listed above, under NVIDIA-SMI > Name.\n",
        "# Tesla K80: 30\n",
        "# Tesla P100: 60\n",
        "# Tesla T4: 75\n",
        "%env compute_capability=60"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: compute_capability=60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23TECXvNezIF"
      },
      "source": [
        "## Run Tensorboard(Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H2PZs-mSCmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e233ac90-abad-47df-ecab-6f5739641407"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-16 13:32:25--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.236.206.131, 35.171.215.128, 3.216.229.131, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.236.206.131|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  37.3MB/s    in 0.4s    \n",
            "\n",
            "2021-02-16 13:32:26 (37.3 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8o6r1o5SC5M"
      },
      "source": [
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge1OX7gcSC7S"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5GSGxZNh8rp"
      },
      "source": [
        "### Get Tensorboard link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjhPT9iPSJ6T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54bd37c8-dff4-4545-8f7c-ba272c751bff"
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://e1d9657c9562.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDddx2rPfex9"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjDHjhKQofT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f17dae5f-b230-4a03-8751-2c86a92632b1"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-16 13:33:26.510581: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "INFO:tensorflow:loss = 45.907066, step = 0\n",
            "I0216 13:33:29.796163 140051179038592 basic_session_run_hooks.py:262] loss = 45.907066, step = 0\n",
            "INFO:tensorflow:Saving checkpoints for 1 into training/model.ckpt.\n",
            "I0216 13:33:29.797242 140051179038592 basic_session_run_hooks.py:606] Saving checkpoints for 1 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cashew.tfrecord']\n",
            "I0216 13:33:31.036759 140051179038592 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cashew.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cashew.tfrecord']\n",
            "I0216 13:33:31.037381 140051179038592 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cashew.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0216 13:33:31.037550 140051179038592 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f5fb0969668>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0216 13:33:31.077502 140051179038592 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f5fb0969668>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f5faf866b70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0216 13:33:31.242546 140051179038592 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f5faf866b70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0216 13:33:31.738255 140051179038592 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0216 13:33:33.680115 140051179038592 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0216 13:33:33.707708 140051179038592 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0216 13:33:33.734571 140051179038592 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0216 13:33:33.761707 140051179038592 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0216 13:33:33.788271 140051179038592 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0216 13:33:33.816081 140051179038592 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:927: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0216 13:33:34.831696 140051179038592 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:927: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0216 13:33:35.011594 140051179038592 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0216 13:33:35.482191 140051179038592 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-02-16T13:33:35Z\n",
            "I0216 13:33:35.497310 140051179038592 evaluation.py:255] Starting evaluation at 2021-02-16T13:33:35Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0216 13:33:35.908050 140051179038592 monitored_session.py:240] Graph was finalized.\n",
            "2021-02-16 13:33:35.909100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 13:33:35.909600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-02-16 13:33:35.909690: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-02-16 13:33:35.909717: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-02-16 13:33:35.909741: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-02-16 13:33:35.909764: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-02-16 13:33:35.909796: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-02-16 13:33:35.909819: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-02-16 13:33:35.909842: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-02-16 13:33:35.909925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 13:33:35.910401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 13:33:35.910844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-02-16 13:33:35.910896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-02-16 13:33:35.910910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-02-16 13:33:35.910920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-02-16 13:33:35.911020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 13:33:35.911499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 13:33:35.911941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-1\n",
            "I0216 13:33:35.912989 140051179038592 saver.py:1284] Restoring parameters from training/model.ckpt-1\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0216 13:33:36.794659 140051179038592 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0216 13:33:36.922826 140051179038592 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 35 images.\n",
            "I0216 13:33:41.240218 140047259830016 coco_evaluation.py:293] Performing evaluation on 35 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0216 13:33:41.241142 140047259830016 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0216 13:33:41.243194 140047259830016 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.09s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "INFO:tensorflow:Finished evaluation at 2021-02-16-13:33:41\n",
            "I0216 13:33:41.878584 140051179038592 evaluation.py:275] Finished evaluation at 2021-02-16-13:33:41\n",
            "INFO:tensorflow:Saving dict for global step 1: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = 0.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = 0.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 33.269146, Loss/localization_loss = 3.0388832, Loss/regularization_loss = 0.30199912, Loss/total_loss = 36.61003, global_step = 1, learning_rate = 0.004, loss = 36.61003\n",
            "I0216 13:33:41.878891 140051179038592 estimator.py:2049] Saving dict for global step 1: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = 0.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = 0.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 33.269146, Loss/localization_loss = 3.0388832, Loss/regularization_loss = 0.30199912, Loss/total_loss = 36.61003, global_step = 1, learning_rate = 0.004, loss = 36.61003\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1: training/model.ckpt-1\n",
            "I0216 13:33:42.725069 140051179038592 estimator.py:2109] Saving 'checkpoint_path' summary for global step 1: training/model.ckpt-1\n",
            "INFO:tensorflow:Performing the final export in the end of training.\n",
            "I0216 13:33:42.725852 140051179038592 exporter.py:410] Performing the final export in the end of training.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0216 13:33:42.979395 140051179038592 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0216 13:33:45.310426 140051179038592 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0216 13:33:45.340921 140051179038592 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0216 13:33:45.370079 140051179038592 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0216 13:33:45.399362 140051179038592 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0216 13:33:45.428677 140051179038592 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0216 13:33:45.463081 140051179038592 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0216 13:33:46.399246 140051179038592 estimator.py:1150] Done calling model_fn.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0216 13:33:46.399542 140051179038592 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "I0216 13:33:46.400137 140051179038592 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "I0216 13:33:46.400248 140051179038592 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "I0216 13:33:46.400325 140051179038592 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "I0216 13:33:46.400397 140051179038592 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "I0216 13:33:46.400460 140051179038592 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
            "2021-02-16 13:33:46.401024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 13:33:46.401638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-02-16 13:33:46.401737: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-02-16 13:33:46.401775: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-02-16 13:33:46.401805: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-02-16 13:33:46.401837: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-02-16 13:33:46.401863: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-02-16 13:33:46.401890: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-02-16 13:33:46.401916: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-02-16 13:33:46.402012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 13:33:46.402549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 13:33:46.402957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-02-16 13:33:46.403000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-02-16 13:33:46.403014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-02-16 13:33:46.403031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-02-16 13:33:46.403130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 13:33:46.403614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 13:33:46.404032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-1\n",
            "I0216 13:33:46.406323 140051179038592 saver.py:1284] Restoring parameters from training/model.ckpt-1\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "I0216 13:33:46.850202 140051179038592 builder_impl.py:665] Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0216 13:33:46.850413 140051179038592 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: training/export/Servo/temp-b'1613482422'/saved_model.pb\n",
            "I0216 13:33:47.594198 140051179038592 builder_impl.py:425] SavedModel written to: training/export/Servo/temp-b'1613482422'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 45.907066.\n",
            "I0216 13:33:47.908825 140051179038592 estimator.py:371] Loss for final step: 45.907066.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP-tUdtnRybs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9741f893-20aa-46f2-b2cb-0f3df3a79b11"
      },
      "source": [
        "!ls {model_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\t\t     model.ckpt-0.index\n",
            "eval_0\t\t\t\t\t     model.ckpt-0.meta\n",
            "events.out.tfevents.1613482370.492e8d34182c  model.ckpt-1.data-00000-of-00001\n",
            "export\t\t\t\t\t     model.ckpt-1.index\n",
            "graph.pbtxt\t\t\t\t     model.ckpt-1.meta\n",
            "model.ckpt-0.data-00000-of-00001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmSESMetj1sa"
      },
      "source": [
        "## Exporting a Trained Inference Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHoP90pUyKSq"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = './fine_tuned_model'\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usgBZvkz0nqD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f26bd52b-9363-435e-e702-6c4bb828495a"
      },
      "source": [
        "!ls {output_directory}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\tmodel.ckpt.index  saved_model\n",
            "frozen_inference_graph.pb\tmodel.ckpt.meta\n",
            "model.ckpt.data-00000-of-00001\tpipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISvrJKqASgug"
      },
      "source": [
        "## Exporter en TFLITE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwXJdICRC7SF"
      },
      "source": [
        "# Exporter en tflite.pb\r\n",
        "!mkdir '/content/tflite'\r\n",
        "!python /content/models/research/object_detection/export_tflite_ssd_graph.py --pipeline_config_path={pipeline_fname} --trained_checkpoint_prefix={last_model_path} --output_directory='/content/tflite' --add_postprocessing_op=true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5wW5A5SSFYi"
      },
      "source": [
        "# Exporter le TFLite.pb en model.tflite\r\n",
        "import tensorflow as tf\r\n",
        "input_arrays = [\"normalized_input_image_tensor\"]\r\n",
        "output_arrays = [\"TFLite_Detection_PostProcess\",\"TFLite_Detection_PostProcess:1\",\"TFLite_Detection_PostProcess:2\",\"TFLite_Detection_PostProcess:3\"]\r\n",
        "input_shapes = {\"normalized_input_image_tensor\" : [1, 300, 300, 3]}\r\n",
        "converter = tf.lite.TFLiteConverter.from_frozen_graph(\r\n",
        "        '/content/tflite/tflite_graph.pb', input_arrays, output_arrays, input_shapes)\r\n",
        "converter.allow_custom_ops = True\r\n",
        "converter.quantized_input_stats = {\"normalized_input_image_tensor\": (128., 127.)}\r\n",
        "tflite_model = converter.convert()\r\n",
        "open(\"/content/ssd.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}